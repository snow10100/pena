import json
from typing_extensions import Annotated, TypedDict, List, Optional, Dict, Literal
from lg_pentest.pentest_agent.utils.model import _get_model
from lg_pentest.pentest_agent.utils.state import PentestState
from langchain_core.messages import SystemMessage, HumanMessage, ToolMessage
# from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_community.tools import ShellTool
# from langgraph.prebuilt import ToolNode

shell_tool = ShellTool()
tools = [shell_tool]
# class Task(BaseModel):
#     """The task that the tools needs to do"""
#     phase: str = Field(description="Current phase of pentesting")
#     task: str = Field(description="Task to perform so that the tool agent succeds.")
#     hints: Optional[List[str]] = Field(description="May contain hints about the task")
#     constraints: Optional[List[str]] = Field(description="Contains constraints that the tool user agent should be aware of")
#     program_name: str = Field(description="program name that the tool uses to finish a task")
#     args: Optinal[dict] = Field(description="args that might help the tool user agent")
#     results: dict = Field(description="Title of findings as keys, and a description as their value")

# class ToolNode:
#     """A node that runs the tools requested in the last AIMessage."""
#
#     def __init__(self, tools: list) -> None:
#         self.tools_by_name = {tool.name: tool for tool in tools}
#
#     def __call__(self, inputs: dict):
#         if messages := inputs.get("messages", []):
#             message = messages[-1]
#         else:
#             raise ValueError("No message found in input")
#         outputs = []
#         for tool_call in message['tool_calls']:
#             tool_result = self.tools_by_name[tool_call["name"]].invoke(
#                 tool_call["args"]
#             )
#             outputs.append(
#                 # ToolMessage(
#                 {
#                     'role': 'tool_call',
#                     'content': json.dumps(tool_result),
#                     # 'name': tool_call["name"],
#                     # 'tool_call_id': tool_call["id"],
#                 }
#             )
#         return {"messages": outputs}

class Task(TypedDict):
    """The task that the tool needs to do"""
    message: str
    # phase: Annotated[str, ... , "Current phase of pentesting"]
    # task: Annotated[str, ... , "Task to perform so that the tool agent succeeds."]
    # hints: Annotated[Optional[List[str]], ... , "May contain hints about the task"]
    # constraints: Annotated[Optional[List[str]], ... , "Contains constraints that the tool user agent should be aware of"]
    # program_name: Annotated[str, ... , "Program name that the tool uses to finish a task"]
    # args: Annotated[Optional[Dict], ... , "Args that might help the tool user agent"]
    # results: Annotated[Dict, ... , "Title of findings as keys, and a description as their value"]
    results: str
    

def _swap_messages(messages):
    new_messages = []
    for m in messages:
        if m['role'] == 'assistant':
            new_messages.append({"role": "user", "content": m['content']})
        else:
            new_messages.append({"role": "assistant", "content": m['content']})
    return new_messages

# tools = ToolNode(tools=[shell_tool])

def tools_node(state: PentestState) -> PentestState:
    system_prompt = SystemMessage(f"""
    You are an AI agent who is an expert in using a tool named {state['tool_name']}, 
    to do {state['pentest_tasks']}. You are working with a team of AI agents, 
    you will receive a task, and possibly hints, constrains, and args. 
    You will have to use your expertise in {state['tool_name']} to finish
    the task. When you are done pass the results to the calling agent. 

    you have access to bash shell using shell_tool
    """)
    print(f'{system_prompt = }')
    human_msg = HumanMessage(content=f"Use {state['tool_name']} to do {state['task']}")
    messages = [system_prompt] + [human_msg]
    model = _get_model().bind_tools(tools)
    ai_msg = model.invoke(messages)
    messages.append(ai_msg)
    for tool_call in ai_msg.tool_calls:
        selected_tool = {tool.name: tool for tool in tools}[tool_call["name"].lower()]
        tool_msg = selected_tool.invoke(tool_call)
        # tool_msg = selected_tool.invoke(tool_call)
        messages.append(tool_msg)
    # tool_msg = shell_tool.invoke(ai_msg.tool_calls)
    # messages.append(tool_msg)
    messages.append(HumanMessage(content='summarize before parsing'))
    model = _get_model().with_structured_output(Task)
    response = model.invoke(messages)
    print(f'tools:\n{response = }')
    return {
            'messages': [{'role': 'assistant',
                          'content': '\n\n'.join(response.values())}],
            'tool_results': response['results'],
            }
